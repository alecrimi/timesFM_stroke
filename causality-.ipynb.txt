{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhuUy0yaYHE2"
      },
      "source": [
        "Testing effective connectivity from time series prediction using foundation models. The initial case is without fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ke61U6fdYCc0"
      },
      "outputs": [],
      "source": [
        "pip install timesfm sktime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zmrxPHoZ68B"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import timesfm\n",
        "import pandas as pd\n",
        "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error, mean_absolute_scaled_error, mean_absolute_error\n",
        "from sktime.forecasting.naive import NaiveForecaster\n",
        "from sktime.forecasting.base import ForecastingHorizon\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sktime.forecasting.compose import make_reduction\n",
        "from sktime.forecasting.statsforecast import StatsForecastAutoARIMA, StatsForecastAutoETS\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from scipy.stats import f\n",
        "from sklearn.linear_model import Ridge, LinearRegression\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"possible convergence problem\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CG4noJEraUbm"
      },
      "outputs": [],
      "source": [
        "##Initialize foundation model without fine tuning\n",
        "tfm = timesfm.TimesFm(\n",
        "      hparams=timesfm.TimesFmHparams(\n",
        "          backend=\"gpu\",\n",
        "          per_core_batch_size=32,\n",
        "          horizon_len=128,\n",
        "      ),\n",
        "      checkpoint=timesfm.TimesFmCheckpoint(\n",
        "          huggingface_repo_id=\"google/timesfm-1.0-200m-pytorch\"),\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XVtzDnUqai1o"
      },
      "outputs": [],
      "source": [
        "##Load time series\n",
        "def load_data(path, verbose = False):\n",
        "    dataset = pd.read_csv(path, sep='\\t', header = None)\n",
        "    if verbose:\n",
        "        print(dataset.columns)\n",
        "        print(len(dataset))\n",
        "        print(dataset.head())\n",
        "    return dataset\n",
        "control_data = load_data('sub-CON001_ses-control_task-rest_space-MNI152NLin2009cAsym_atlas-Schaefer117_timeseries.tsv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "r2KOXFQVbCQ3"
      },
      "outputs": [],
      "source": [
        "# convert the structure to be read by the model\n",
        "def split_train_test(data, break_index):\n",
        "    split = data.index < break_index\n",
        "    return data[split], data[~split]\n",
        "control_data_train, control_data_test = split_train_test(control_data, 300)\n",
        "\n",
        "def convert_to_timefm(data):\n",
        "    data_time_fm = []\n",
        "    for col in data.columns:\n",
        "        data_time_fm += [data[col]]\n",
        "    return data_time_fm\n",
        "control_data_train_for_time_fm = convert_to_timefm(control_data_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5IkaiWnc01E"
      },
      "outputs": [],
      "source": [
        "# Individual prediction #RUN only for test\n",
        "# freq=[0] means no seasonality\n",
        "#predicted = tfm.forecast(control_data_train_for_time_fm, freq=[0] * len(control_data_train.columns))[0]\n",
        "#predicted = tfm.forecast(control_data_train_for_time_fm, freq=[0] * len(control_data_train_for_time_fm.columns))[0] #adding this will check only one series [0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# LLM Granger-like Causality (for preprocessed data)\n",
        "new_horizon = len(control_data_test.iloc[:, 0])\n",
        "\n",
        "def safe_timesfm_forecast(series_data, new_horizon):\n",
        "    \"\"\"TimesFM forecast for preprocessed fMRI data\"\"\"\n",
        "    try:\n",
        "        if hasattr(series_data, 'values'):\n",
        "            data = series_data.values\n",
        "        else:\n",
        "            data = np.array(series_data)\n",
        "\n",
        "        data = data.flatten()\n",
        "        data = data[np.isfinite(data)]\n",
        "\n",
        "        if len(data) == 0:\n",
        "            raise ValueError(\"No valid data\")\n",
        "\n",
        "        # TimesFM forecast\n",
        "        predicted = tfm.forecast([data], freq=[0])[0]\n",
        "        return predicted[0, :new_horizon], \"timesfm\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    TimesFM failed: {e}, using AR(1) fallback\")\n",
        "        return ar1_forecast_simple(data, new_horizon), \"ar1_fallback\"\n",
        "\n",
        "def ar1_forecast_simple(data, horizon):\n",
        "    \"\"\"Simple AR(1) model as fallback\"\"\"\n",
        "    if len(data) < 3:\n",
        "        return np.full(horizon, np.mean(data) if len(data) > 0 else 0)\n",
        "\n",
        "    # Fit AR(1): y_t = c + φ*y_{t-1} + ε_t\n",
        "    y = data[1:]\n",
        "    x = data[:-1]\n",
        "\n",
        "    try:\n",
        "        # Simple linear regression\n",
        "        phi = np.cov(x, y)[0, 1] / np.var(x)\n",
        "        c = np.mean(y) - phi * np.mean(x)\n",
        "\n",
        "        # Multi-step forecast\n",
        "        forecast = []\n",
        "        last_val = data[-1]\n",
        "\n",
        "        for _ in range(horizon):\n",
        "            next_val = c + phi * last_val\n",
        "            forecast.append(next_val)\n",
        "            last_val = next_val\n",
        "\n",
        "        return np.array(forecast)\n",
        "\n",
        "    except:\n",
        "        return np.full(horizon, np.mean(data))\n",
        "\n",
        "def compute_lag1_covariate_effect(target_series, covariate_series):\n",
        "    \"\"\"\n",
        "    Compute lag-1 covariate effect: target[t] ~ covariate[t-1]\n",
        "    Returns coefficient and model improvement\n",
        "    \"\"\"\n",
        "    target_vals = np.array(target_series).flatten()\n",
        "    cov_vals = np.array(covariate_series).flatten()\n",
        "\n",
        "    # Align series length\n",
        "    min_len = min(len(target_vals), len(cov_vals))\n",
        "    if min_len < 15:  # Need reasonable sample size\n",
        "        return 0, 0, 0, \"insufficient_data\"\n",
        "\n",
        "    target_vals = target_vals[:min_len]\n",
        "    cov_vals = cov_vals[:min_len]\n",
        "\n",
        "    # Create lag-1 relationship\n",
        "    y = target_vals[1:]              # target from t=1 onwards\n",
        "    x_target_lag = target_vals[:-1]  # target[t-1]\n",
        "    x_cov_lag = cov_vals[:-1]        # covariate[t-1]\n",
        "\n",
        "    try:\n",
        "        # Restricted model: target[t] = α + β*target[t-1] + ε\n",
        "        X_restricted = np.column_stack([np.ones(len(y)), x_target_lag])\n",
        "        coeffs_restricted = np.linalg.lstsq(X_restricted, y, rcond=None)[0]\n",
        "        y_pred_restricted = X_restricted @ coeffs_restricted\n",
        "        rss_restricted = np.sum((y - y_pred_restricted) ** 2)\n",
        "\n",
        "        # Full model: target[t] = α + β*target[t-1] + γ*covariate[t-1] + ε\n",
        "        X_full = np.column_stack([np.ones(len(y)), x_target_lag, x_cov_lag])\n",
        "        coeffs_full = np.linalg.lstsq(X_full, y, rcond=None)[0]\n",
        "        y_pred_full = X_full @ coeffs_full\n",
        "        rss_full = np.sum((y - y_pred_full) ** 2)\n",
        "\n",
        "        # Extract covariate coefficient\n",
        "        covariate_coeff = coeffs_full[2]\n",
        "        rss_improvement = rss_restricted - rss_full\n",
        "\n",
        "        # Calculate R-squared improvement\n",
        "        tss = np.sum((y - np.mean(y)) ** 2)\n",
        "        r2_restricted = 1 - (rss_restricted / tss)\n",
        "        r2_full = 1 - (rss_full / tss)\n",
        "        r2_improvement = r2_full - r2_restricted\n",
        "\n",
        "        return covariate_coeff, rss_improvement, r2_improvement, \"success\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return 0, 0, 0, f\"failed_{e}\"\n",
        "\n",
        "def forecast_with_lag1_covariate(target_series, covariate_series, new_horizon):\n",
        "    \"\"\"\n",
        "    Forecast using lag-1 covariate relationship for fMRI\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Get baseline TimesFM forecast\n",
        "        baseline_forecast, baseline_method = safe_timesfm_forecast(target_series, new_horizon)\n",
        "\n",
        "        # Compute lag-1 covariate effect\n",
        "        cov_coeff, rss_improvement, r2_improvement, effect_status = compute_lag1_covariate_effect(\n",
        "            target_series, covariate_series\n",
        "        )\n",
        "\n",
        "        if effect_status != \"success\" or abs(cov_coeff) < 0.01 or r2_improvement < 0.001:\n",
        "            return baseline_forecast, \"no_covariate_effect\", cov_coeff, r2_improvement\n",
        "\n",
        "        # For forecasting, we need to project the covariate influence\n",
        "        target_vals = np.array(target_series).flatten()\n",
        "        cov_vals = np.array(covariate_series).flatten()\n",
        "\n",
        "        # Simple approach: assume covariate stays at its recent average for forecast period\n",
        "        recent_cov_window = min(10, len(cov_vals))\n",
        "        recent_cov_mean = np.mean(cov_vals[-recent_cov_window:])\n",
        "\n",
        "        # Alternative: use trend\n",
        "        if len(cov_vals) >= 5:\n",
        "            recent_trend = np.mean(np.diff(cov_vals[-5:]))\n",
        "        else:\n",
        "            recent_trend = 0\n",
        "\n",
        "        # Create covariate adjustments\n",
        "        adjustments = []\n",
        "        current_cov = cov_vals[-1] if len(cov_vals) > 0 else 0\n",
        "\n",
        "        for step in range(new_horizon):\n",
        "            # Project covariate value (using trend + mean reversion)\n",
        "            projected_cov = current_cov + step * recent_trend * 0.5  # Damped trend\n",
        "\n",
        "            # Apply covariate effect with decay over forecast horizon\n",
        "            decay_factor = 0.95 ** step  # Effect decays over time\n",
        "            adjustment = cov_coeff * projected_cov * decay_factor\n",
        "            adjustments.append(adjustment)\n",
        "\n",
        "        # Combine baseline with covariate adjustments\n",
        "        adjusted_forecast = baseline_forecast + np.array(adjustments)\n",
        "\n",
        "        return adjusted_forecast, \"covariate_adjusted\", cov_coeff, r2_improvement\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    Covariate adjustment failed: {e}\")\n",
        "        baseline_forecast, _ = safe_timesfm_forecast(target_series, new_horizon)\n",
        "        return baseline_forecast, \"fallback\", 0, 0\n",
        "\n",
        "def enhanced_granger_test_fmri(target_test, pred_restricted, pred_full):\n",
        "    \"\"\"\n",
        "    Enhanced statistical test for fMRI Granger causality\n",
        "    Uses multiple approaches to increase sensitivity\n",
        "    \"\"\"\n",
        "    min_len = min(len(target_test), len(pred_restricted), len(pred_full))\n",
        "    if min_len < 8:  # Need minimum observations\n",
        "        return np.nan, 1.0, \"insufficient_data\"\n",
        "\n",
        "    y_true = np.array(target_test[:min_len])\n",
        "    y_restricted = np.array(pred_restricted[:min_len])\n",
        "    y_full = np.array(pred_full[:min_len])\n",
        "\n",
        "    # Calculate prediction errors\n",
        "    errors_restricted = y_true - y_restricted\n",
        "    errors_full = y_true - y_full\n",
        "\n",
        "    # Method 1: Standard F-test\n",
        "    RSS_restricted = np.sum(errors_restricted ** 2)\n",
        "    RSS_full = np.sum(errors_full ** 2)\n",
        "\n",
        "    # Check for improvement\n",
        "    if RSS_full >= RSS_restricted * 0.99:  # Allow for small numerical differences\n",
        "        return 0.0, 1.0, \"no_improvement\"\n",
        "\n",
        "    # F-test calculation\n",
        "    n = min_len\n",
        "    k = 1  # One additional parameter (covariate effect)\n",
        "\n",
        "    if RSS_full > 0:\n",
        "        f_stat = ((RSS_restricted - RSS_full) / k) / (RSS_full / (n - 2))\n",
        "        if f_stat > 0:\n",
        "            p_val_f = 1 - f.cdf(f_stat, k, n - 2)\n",
        "        else:\n",
        "            p_val_f = 1.0\n",
        "    else:\n",
        "        f_stat = 0.0\n",
        "        p_val_f = 1.0\n",
        "\n",
        "    # Method 2: Paired t-test on absolute errors (more sensitive for time series)\n",
        "    try:\n",
        "        abs_errors_restricted = np.abs(errors_restricted)\n",
        "        abs_errors_full = np.abs(errors_full)\n",
        "\n",
        "        # One-sided paired t-test: are full model errors smaller?\n",
        "        from scipy.stats import ttest_rel\n",
        "        t_stat, p_val_t = ttest_rel(abs_errors_restricted, abs_errors_full,\n",
        "                                   alternative='greater')\n",
        "\n",
        "        # Use the more significant result\n",
        "        if p_val_t < p_val_f:\n",
        "            return t_stat, p_val_t, \"paired_ttest_abs_errors\"\n",
        "        else:\n",
        "            return f_stat, p_val_f, \"f_test\"\n",
        "\n",
        "    except:\n",
        "        return f_stat, p_val_f, \"f_test_only\"\n",
        "\n",
        "# === Main execution ===\n",
        "print(\"=== fMRI-Optimized LLM Granger Causality (Preprocessed Data) ===\")\n",
        "print(f\"Forecast horizon: {new_horizon} time points\")\n",
        "print(\"Using lag-1 relationships for fMRI temporal dynamics\\n\")\n",
        "\n",
        "all_results = []\n",
        "\n",
        "for target_index in range(len(control_data.columns)):\n",
        "    target_name = control_data.columns[target_index]\n",
        "    print(f\"=== Target: {target_name} ===\")\n",
        "\n",
        "    target_train = control_data_train.iloc[:, target_index]\n",
        "    target_test = control_data_test.iloc[:, target_index]\n",
        "\n",
        "    # Baseline forecast (restricted model)\n",
        "    try:\n",
        "        pred_baseline, baseline_method = safe_timesfm_forecast(target_train, new_horizon)\n",
        "        mse_baseline = mean_squared_error(target_test, pred_baseline)\n",
        "        print(f\"Baseline MSE: {mse_baseline:.6f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Baseline forecast failed: {e}\")\n",
        "        continue\n",
        "\n",
        "    target_results = []\n",
        "\n",
        "    for cov_index in range(len(control_data.columns)):\n",
        "        if cov_index == target_index:\n",
        "            continue\n",
        "\n",
        "        cov_name = control_data.columns[cov_index]\n",
        "        covariate_train = control_data_train.iloc[:, cov_index]\n",
        "\n",
        "        # Full model forecast with covariate\n",
        "        pred_full, method_used, cov_coeff, r2_improvement = forecast_with_lag1_covariate(\n",
        "            target_train, covariate_train, new_horizon\n",
        "        )\n",
        "\n",
        "        # Calculate performance metrics\n",
        "        mse_full = mean_squared_error(target_test, pred_full)\n",
        "        mse_improvement_pct = (mse_baseline - mse_full) / mse_baseline * 100\n",
        "\n",
        "        # Statistical test\n",
        "        test_stat, p_value, test_method = enhanced_granger_test_fmri(\n",
        "            target_test, pred_baseline, pred_full\n",
        "        )\n",
        "\n",
        "        result = {\n",
        "            'target': target_name,\n",
        "            'covariate': cov_name,\n",
        "            'mse_baseline': mse_baseline,\n",
        "            'mse_full': mse_full,\n",
        "            'mse_improvement_pct': mse_improvement_pct,\n",
        "            'covariate_coeff': cov_coeff,\n",
        "            'r2_improvement': r2_improvement,\n",
        "            'test_stat': test_stat,\n",
        "            'p_value': p_value,\n",
        "            'test_method': test_method,\n",
        "            'forecast_method': method_used\n",
        "        }\n",
        "\n",
        "        target_results.append(result)\n",
        "        all_results.append(result)\n",
        "\n",
        "        # Print detailed results for promising cases\n",
        "        #if p_value < 0.2 or mse_improvement_pct > 1:\n",
        "        if 1==1:\n",
        "            print(f\"  {cov_name}: p={p_value:.4f}, MSE_improve={mse_improvement_pct:.2f}%, \"\n",
        "                  f\"coeff={cov_coeff:.4f}, R²_improve={r2_improvement:.4f}\")\n",
        "\n",
        "    print()\n",
        "\n",
        "# Summary of all results\n",
        "print(\"=== SUMMARY ===\")\n",
        "\n",
        "# Sort all results by p-value\n",
        "all_results.sort(key=lambda x: x['p_value'])\n",
        "\n",
        "# Show significant results\n",
        "significant_05 = [r for r in all_results if r['p_value'] < 0.05]\n",
        "significant_10 = [r for r in all_results if 0.05 <= r['p_value'] < 0.10]\n",
        "marginal_20 = [r for r in all_results if 0.10 <= r['p_value'] < 0.20]\n",
        "\n",
        "print(f\"Significant results (p < 0.05): {len(significant_05)}\")\n",
        "for r in significant_05:\n",
        "    print(f\"  {r['covariate']} -> {r['target']}: p={r['p_value']:.4f}, \"\n",
        "          f\"improve={r['mse_improvement_pct']:.2f}%\")\n",
        "\n",
        "print(f\"\\nMarginal results (0.05 ≤ p < 0.10): {len(significant_10)}\")\n",
        "for r in significant_10:\n",
        "    print(f\"  {r['covariate']} -> {r['target']}: p={r['p_value']:.4f}, \"\n",
        "          f\"improve={r['mse_improvement_pct']:.2f}%\")\n",
        "\n",
        "print(f\"\\nWeaker evidence (0.10 ≤ p < 0.20): {len(marginal_20)}\")\n",
        "for r in marginal_20:\n",
        "    print(f\"  {r['covariate']} -> {r['target']}: p={r['p_value']:.4f}, \"\n",
        "          f\"improve={r['mse_improvement_pct']:.2f}%\")\n",
        "\n",
        "# Show best forecast improvements regardless of p-value\n",
        "print(f\"\\nBest forecast improvements (top 5):\")\n",
        "best_improvements = sorted(all_results, key=lambda x: x['mse_improvement_pct'], reverse=True)[:5]\n",
        "for i, r in enumerate(best_improvements, 1):\n",
        "    print(f\"  {i}. {r['covariate']} -> {r['target']}: {r['mse_improvement_pct']:.2f}% improve, \"\n",
        "          f\"p={r['p_value']:.4f}\")\n",
        "\n",
        "print(f\"\\nTotal relationships tested: {len(all_results)}\")"
      ],
      "metadata": {
        "id": "XZREWnMKWfy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "display(None)  # this clears widget state"
      ],
      "metadata": {
        "id": "BmOPsxWCjc6C"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}