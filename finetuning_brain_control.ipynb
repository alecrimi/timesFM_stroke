{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning on and evaluating control data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuning based on: https://github.com/google-research/timesfm/blob/master/notebooks/finetuning.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing relevant packages for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "os.environ['JAX_PMAP_USE_TENSORSTORE'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimesFM v1.2.0. See https://github.com/google-research/timesfm/blob/master/README.md for updated APIs.\n",
      "Loaded Jax TimesFM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 15:26:16.271933: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import timesfm\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timesfm import patched_decoder\n",
    "from timesfm import data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import dataclasses\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading TimesFM pretrained checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c449e8d61a464db9baa3ab124e35d51a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiprocessing context has already been set.\n",
      "Constructing model weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No registered CheckpointArgs found for handler type: <class 'paxml.checkpoints.FlaxCheckpointHandler'>\n",
      "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n",
      "WARNING:absl:train_state_unpadded_shape_dtype_struct is not provided. We assume `train_state` is unpadded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed model weights in 3.76 seconds.\n",
      "Restoring checkpoint from /home/julian/.cache/huggingface/hub/models--google--timesfm-2.0-500m-jax/snapshots/47dedfcadf2abace1cc96071ddb798cfcd3bfcef/checkpoints.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:absl:For checkpoint version > 1.0, we require users to provide\n",
      "          `train_state_unpadded_shape_dtype_struct` during checkpoint\n",
      "          saving/restoring, to avoid potential silent bugs when loading\n",
      "          checkpoints to incompatible unpadded shapes of TrainState.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint in 0.47 seconds.\n",
      "Jitting decoding.\n",
      "Jitted decoding in 22.49 seconds.\n"
     ]
    }
   ],
   "source": [
    "timesfm_backend = \"gpu\"  # @param\n",
    "\n",
    "tfm = timesfm.TimesFm(\n",
    "      hparams=timesfm.TimesFmHparams(\n",
    "          backend=timesfm_backend,\n",
    "          per_core_batch_size=32,\n",
    "          horizon_len=128,\n",
    "          num_layers=50,\n",
    "          # Se this to True for v1.0 checkpoints\n",
    "          use_positional_embedding=False,\n",
    "          # Note that we could set this to as high as 2048 but keeping it 512 here so that\n",
    "          # both v1.0 and 2.0 checkpoints work\n",
    "          context_len=512,\n",
    "      ),\n",
    "      checkpoint=timesfm.TimesFmCheckpoint(\n",
    "          huggingface_repo_id=\"google/timesfm-2.0-500m-jax\"),\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating pretrained checkpoint on control subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can select subject - finetuning was done on control 006 - `con_006`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DICT = {\n",
    "    \"braincon\": {\n",
    "        \"boundaries\": [600, 700, 825],\n",
    "        \"data_path\": \"./datasets/brain/con_006.csv\",\n",
    "        # \"data_path\": \"./datasets/brain/con_009.csv\",\n",
    "        # \"data_path\": \"./datasets/brain/con_012.csv\",\n",
    "        \"freq\": \"H\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the evaluation, we will set context length to `50` and prediction length to `10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julian/studia/mlnn2024/brain-timeseries-prediction/venv/lib/python3.10/site-packages/timesfm/data_loader.py:90: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pd.date_range(\n"
     ]
    }
   ],
   "source": [
    "dataset = \"braincon\"\n",
    "data_path = DATA_DICT[dataset][\"data_path\"]\n",
    "freq = DATA_DICT[dataset][\"freq\"]\n",
    "int_freq = timesfm.freq_map(freq)\n",
    "boundaries = DATA_DICT[dataset][\"boundaries\"]\n",
    "\n",
    "data_df = pd.read_csv(open(data_path, \"r\"))\n",
    "\n",
    "\n",
    "ts_cols = [col for col in data_df.columns if col != \"date\"]\n",
    "num_cov_cols = None\n",
    "cat_cov_cols = None\n",
    "\n",
    "context_len = 50\n",
    "pred_len = 10\n",
    "\n",
    "num_ts = len(ts_cols)\n",
    "batch_size = 8\n",
    "\n",
    "dtl = data_loader.TimeSeriesdata(\n",
    "      data_path=data_path,\n",
    "      datetime_col=\"date\",\n",
    "      num_cov_cols=num_cov_cols,\n",
    "      cat_cov_cols=cat_cov_cols,\n",
    "      ts_cols=np.array(ts_cols),\n",
    "      train_range=[0, boundaries[0]],\n",
    "      val_range=[boundaries[0], boundaries[1]],\n",
    "      test_range=[boundaries[1], boundaries[2]],\n",
    "      hist_len=context_len,\n",
    "      pred_len=pred_len,\n",
    "      batch_size=num_ts,\n",
    "      freq=freq,\n",
    "      normalize=True,\n",
    "      epoch_len=None,\n",
    "      holiday=False,\n",
    "      permute=True,\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating datasets for training, validation, and testing phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 15:26:49.400330: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-01-19 15:26:49.400387: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2025-01-19 15:26:49.400415: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2025-01-19 15:26:49.400452: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2025-01-19 15:26:49.403997: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2025-01-19 15:26:49.404014: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "train_batches = dtl.tf_dataset(mode=\"train\", shift=1).batch(batch_size)\n",
    "val_batches = dtl.tf_dataset(mode=\"val\", shift=pred_len)\n",
    "test_batches = dtl.tf_dataset(mode=\"test\", shift=pred_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 100, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for tbatch in tqdm(train_batches.as_numpy_iterator()):\n",
    "    break\n",
    "print(tbatch[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE on the test split for the pretrained TimesFM model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7329540178425975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mae_losses = []\n",
    "for batch in tqdm(test_batches.as_numpy_iterator()):\n",
    "    past = batch[0]\n",
    "    actuals = batch[3]\n",
    "    forecasts, _ = tfm.forecast(list(past), [0] * past.shape[0], normalize=True)\n",
    "    forecasts = forecasts[:, 0 : actuals.shape[1]]\n",
    "    mae_losses.append(np.abs(forecasts - actuals).mean())\n",
    "\n",
    "print(f\"MAE: {np.mean(mae_losses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on base model for different subjects\n",
    "\n",
    "We run the model for each control subject and calculate the MAE:\n",
    "\n",
    "* Control 006 - MAE: 0.73295\n",
    "\n",
    "* Control 009 - MAE: 0.75928\n",
    "\n",
    "* Control 012 - MAE: 0.93567"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning the model on the control subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from praxis import pax_fiddle\n",
    "from praxis import py_utils\n",
    "from praxis import pytypes\n",
    "from praxis import base_model\n",
    "from praxis import optimizers\n",
    "from praxis import schedules\n",
    "from praxis import base_hyperparams\n",
    "from praxis import base_layer\n",
    "from paxml import tasks_lib\n",
    "from paxml import trainer_lib\n",
    "from paxml import checkpoints\n",
    "from paxml import learners\n",
    "from paxml import partitioning\n",
    "from paxml import checkpoint_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAX shortcuts\n",
    "NestedMap = py_utils.NestedMap\n",
    "WeightInit = base_layer.WeightInit\n",
    "WeightHParams = base_layer.WeightHParams\n",
    "InstantiableParams = py_utils.InstantiableParams\n",
    "JTensor = pytypes.JTensor\n",
    "NpTensor = pytypes.NpTensor\n",
    "WeightedScalars = pytypes.WeightedScalars\n",
    "instantiate = base_hyperparams.instantiate\n",
    "LayerTpl = pax_fiddle.Config[base_layer.BaseLayer]\n",
    "AuxLossStruct = base_layer.AuxLossStruct\n",
    "\n",
    "AUX_LOSS = base_layer.AUX_LOSS\n",
    "template_field = base_layer.template_field\n",
    "\n",
    "# Standard prng key names\n",
    "PARAMS = base_layer.PARAMS\n",
    "RANDOM = base_layer.RANDOM\n",
    "\n",
    "key = jax.random.PRNGKey(seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pax_fiddle.Config(\n",
    "    patched_decoder.PatchedDecoderFinetuneModel,\n",
    "    name='patched_decoder_finetune',\n",
    "    core_layer_tpl=tfm.model_p,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will hold the transformer layers fixed while finetuning, while training all other components (linear probing)\n",
    "\n",
    "Linear probing is used to evaluate the quality of the representations learned by a pre-trained model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pax_fiddle.auto_config\n",
    "def build_learner() -> learners.Learner:\n",
    "  return pax_fiddle.Config(\n",
    "      learners.Learner,\n",
    "      name='learner',\n",
    "      loss_name='avg_qloss',\n",
    "      optimizer=optimizers.Adam(\n",
    "          epsilon=1e-7,\n",
    "          clip_threshold=1e2,\n",
    "          learning_rate=1e-2,\n",
    "          lr_schedule=pax_fiddle.Config(\n",
    "              schedules.Cosine,\n",
    "              initial_value=1e-3,\n",
    "              final_value=1e-4,\n",
    "              total_steps=40000,\n",
    "          ),\n",
    "          ema_decay=0.9999,\n",
    "      ),\n",
    "      # Linear probing i.e we hold the transformer layers fixed.\n",
    "      bprop_variable_exclusion=['.*/stacked_transformer_layer/.*'],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_p = tasks_lib.SingleTask(\n",
    "    name='ts-learn',\n",
    "    model=model,\n",
    "    train=tasks_lib.SingleTask.Train(\n",
    "        learner=build_learner(),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_devices: 1\n",
      "device kind: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "task_p.model.ici_mesh_shape = [1, 1, 1]\n",
    "task_p.model.mesh_axis_names = ['replica', 'data', 'mdl']\n",
    "\n",
    "DEVICES = np.array(jax.devices()).reshape([1, 1, 1])\n",
    "MESH = jax.sharding.Mesh(DEVICES, ['replica', 'data', 'mdl'])\n",
    "\n",
    "num_devices = jax.local_device_count()\n",
    "print(f'num_devices: {num_devices}')\n",
    "print(f'device kind: {jax.local_devices()[0].device_kind}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax_task = task_p\n",
    "key, init_key = jax.random.split(key)\n",
    "\n",
    "# To correctly prepare a batch of data for model initialization (now that shape\n",
    "# inference is merged), we take one devices*batch_size tensor tuple of data,\n",
    "# slice out just one batch, then run the prepare_input_batch function over it.\n",
    "\n",
    "\n",
    "def process_train_batch(batch):\n",
    "    past_ts = batch[0].reshape(batch_size * num_ts, -1)\n",
    "    actual_ts = batch[3].reshape(batch_size * num_ts, -1)\n",
    "    return NestedMap(input_ts=past_ts, actual_ts=actual_ts)\n",
    "\n",
    "\n",
    "def process_eval_batch(batch):\n",
    "    past_ts = batch[0]\n",
    "    actual_ts = batch[3]\n",
    "    return NestedMap(input_ts=past_ts, actual_ts=actual_ts)\n",
    "\n",
    "\n",
    "jax_model_states, _ = trainer_lib.initialize_model_state(\n",
    "    jax_task,\n",
    "    init_key,\n",
    "    process_train_batch(tbatch),\n",
    "    checkpoint_type=checkpoint_types.CheckpointType.GDA,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the initial model weights to the pretrained TimesFM parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax_model_states.mdl_vars['params']['core_layer'] = tfm._train_state.mdl_vars['params']\n",
    "jax_vars = jax_model_states.mdl_vars\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax_task = task_p\n",
    "\n",
    "\n",
    "def train_step(states, prng_key, inputs):\n",
    "  return trainer_lib.train_step_single_learner(\n",
    "      jax_task, states, prng_key, inputs\n",
    "  )\n",
    "\n",
    "\n",
    "def eval_step(states, prng_key, inputs):\n",
    "  states = states.to_eval_state()\n",
    "  return trainer_lib.eval_step_single_learner(\n",
    "      jax_task, states, prng_key, inputs\n",
    "  )\n",
    "\n",
    "key, train_key, eval_key = jax.random.split(key, 3)\n",
    "train_prng_seed = jax.random.split(train_key, num=jax.local_device_count())\n",
    "eval_prng_seed = jax.random.split(eval_key, num=jax.local_device_count())\n",
    "\n",
    "p_train_step = jax.pmap(train_step, axis_name='batch')\n",
    "p_eval_step = jax.pmap(eval_step, axis_name='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "replicated_jax_states = trainer_lib.replicate_model_state(jax_model_states)\n",
    "replicated_jax_vars = replicated_jax_states.mdl_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_eval_loss = 1e7\n",
    "step_count = 0\n",
    "patience = 0\n",
    "NUM_EPOCHS = 100\n",
    "PATIENCE = 5\n",
    "TRAIN_STEPS_PER_EVAL = 1000\n",
    "CHECKPOINT_DIR='./finetuned_models/brain_con_finetuned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_batch_for_pmap(batch, num_devices):\n",
    "  def _reshape(input_tensor):\n",
    "    bsize = input_tensor.shape[0]\n",
    "    residual_shape = list(input_tensor.shape[1:])\n",
    "    nbsize = bsize // num_devices\n",
    "    return jnp.reshape(input_tensor, [num_devices, nbsize] + residual_shape)\n",
    "\n",
    "  return jax.tree.map(_reshape, batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncomment to create finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(NUM_EPOCHS):\n",
    "#     print(f\"__________________Epoch: {epoch}__________________\", flush=True)\n",
    "#     train_its = train_batches.as_numpy_iterator()\n",
    "#     if patience >= PATIENCE:\n",
    "#         print(\"Early stopping.\", flush=True)\n",
    "#         break\n",
    "#     for batch in tqdm(train_its):\n",
    "#         train_losses = []\n",
    "#         if patience >= PATIENCE:\n",
    "#             print(\"Early stopping.\", flush=True)\n",
    "#             break\n",
    "#         tbatch = process_train_batch(batch)\n",
    "#         tbatch = reshape_batch_for_pmap(tbatch, num_devices)\n",
    "#         replicated_jax_states, step_fun_out = p_train_step(\n",
    "#             replicated_jax_states, train_prng_seed, tbatch\n",
    "#         )\n",
    "#         train_losses.append(step_fun_out.loss[0])\n",
    "#         if step_count % TRAIN_STEPS_PER_EVAL == 0:\n",
    "#             print(\n",
    "#                 f\"Train loss at step {step_count}: {np.mean(train_losses)}\",\n",
    "#                 flush=True,\n",
    "#             )\n",
    "#             train_losses = []\n",
    "#             print(\"Starting eval.\", flush=True)\n",
    "#             val_its = val_batches.as_numpy_iterator()\n",
    "#             eval_losses = []\n",
    "#             for ev_batch in tqdm(val_its):\n",
    "#                 ebatch = process_eval_batch(ev_batch)\n",
    "#                 ebatch = reshape_batch_for_pmap(ebatch, num_devices)\n",
    "#                 _, step_fun_out = p_eval_step(\n",
    "#                     replicated_jax_states, eval_prng_seed, ebatch\n",
    "#                 )\n",
    "#                 eval_losses.append(step_fun_out.loss[0])\n",
    "#             mean_loss = np.mean(eval_losses)\n",
    "#             print(f\"Eval loss at step {step_count}: {mean_loss}\", flush=True)\n",
    "#             if mean_loss < best_eval_loss or np.isnan(mean_loss):\n",
    "#                 best_eval_loss = mean_loss\n",
    "#                 print(\"Saving checkpoint.\")\n",
    "#                 jax_state_for_saving = py_utils.maybe_unreplicate_for_fully_replicated(\n",
    "#                     replicated_jax_states\n",
    "#                 )\n",
    "#                 checkpoints.save_checkpoint(\n",
    "#                     jax_state_for_saving, CHECKPOINT_DIR, overwrite=True\n",
    "#                 )\n",
    "#                 patience = 0\n",
    "#                 del jax_state_for_saving\n",
    "#                 gc.collect()\n",
    "#             else:\n",
    "#                 patience += 1\n",
    "#                 print(f\"patience: {patience}\")\n",
    "#         step_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and evaluating the best (according to validation loss) finetuned checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No registered CheckpointArgs found for handler type: <class 'paxml.checkpoints.FlaxCheckpointHandler'>\n",
      "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n",
      "WARNING:absl:train_state_unpadded_shape_dtype_struct is not provided. We assume `train_state` is unpadded.\n",
      "ERROR:absl:For checkpoint version > 1.0, we require users to provide\n",
      "          `train_state_unpadded_shape_dtype_struct` during checkpoint\n",
      "          saving/restoring, to avoid potential silent bugs when loading\n",
      "          checkpoints to incompatible unpadded shapes of TrainState.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5001\n",
      "Jitting decoding.\n",
      "Jitted decoding in 19.29 seconds.\n"
     ]
    }
   ],
   "source": [
    "train_state = checkpoints.restore_checkpoint(jax_model_states, CHECKPOINT_DIR)\n",
    "print(train_state.step)\n",
    "tfm._train_state.mdl_vars['params'] = train_state.mdl_vars['params']['core_layer']\n",
    "tfm.jit_decode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6789627075195312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mae_losses = []\n",
    "for batch in tqdm(test_batches.as_numpy_iterator()):\n",
    "    past = batch[0]\n",
    "    actuals = batch[3]\n",
    "    _, forecasts = tfm.forecast(list(past), [0] * past.shape[0])\n",
    "    forecasts = forecasts[:, 0 : actuals.shape[1], 5]\n",
    "    mae_losses.append(np.abs(forecasts - actuals).mean())\n",
    "\n",
    "print(f\"MAE: {np.mean(mae_losses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on control 006 finetuned model for different subjects:\n",
    "\n",
    "* Control 006 (finetuned to) - MAE: 0.67896\n",
    "\n",
    "* Control 009 - MAE: 0.64537\n",
    "\n",
    "* Control 012 - MAE: 0.90034"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and evaluating checkpoint finetuned on PATIENT (here we evaluate control)\n",
    "\n",
    "This checkpoint was created in finetune_brain_patient.ipynb file. Here we want to see what results we get on control data using the model finetuned on patient data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No registered CheckpointArgs found for handler type: <class 'paxml.checkpoints.FlaxCheckpointHandler'>\n",
      "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n",
      "WARNING:absl:train_state_unpadded_shape_dtype_struct is not provided. We assume `train_state` is unpadded.\n",
      "ERROR:absl:For checkpoint version > 1.0, we require users to provide\n",
      "          `train_state_unpadded_shape_dtype_struct` during checkpoint\n",
      "          saving/restoring, to avoid potential silent bugs when loading\n",
      "          checkpoints to incompatible unpadded shapes of TrainState.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n",
      "Jitting decoding.\n",
      "Jitted decoding in 16.07 seconds.\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_DIR='./finetuned_models/brain_pat_finetuned' # Model finetuned on patient\n",
    "\n",
    "train_state = checkpoints.restore_checkpoint(jax_model_states, CHECKPOINT_DIR)\n",
    "print(train_state.step)\n",
    "tfm._train_state.mdl_vars['params'] = train_state.mdl_vars['params']['core_layer']\n",
    "tfm.jit_decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6684911847114563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mae_losses = []\n",
    "for batch in tqdm(test_batches.as_numpy_iterator()):\n",
    "    past = batch[0]\n",
    "    actuals = batch[3]\n",
    "    _, forecasts = tfm.forecast(list(past), [0] * past.shape[0])\n",
    "    forecasts = forecasts[:, 0 : actuals.shape[1], 5]\n",
    "    mae_losses.append(np.abs(forecasts - actuals).mean())\n",
    "\n",
    "print(f\"MAE: {np.mean(mae_losses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on PATIENT finetuned model for different subjects:\n",
    "\n",
    "* Control 006 - MAE: 0.66849\n",
    "\n",
    "* Control 009 - MAE: 0.62142\n",
    "\n",
    "* Control 012 - MAE: 0.83319"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Subject          | Base Model MAE | Control 006 Finetuned MAE | % Decrease (Control 006) | PATIENT Finetuned MAE | % Decrease (PATIENT) |\n",
    "|-------------------|----------------|----------------------------|---------------------------|-----------------------|-----------------------|\n",
    "| Control 006       | 0.73295        | 0.67896                    | 7.99%                     | 0.66849               | 8.80%                 |\n",
    "| Control 009       | 0.75928        | 0.64537                    | 15.03%                    | 0.62142               | 18.19%                |\n",
    "| Control 012       | 0.93567        | 0.90034                    | 3.77%                     | 0.83319               | 11.00%                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly we can see that for every tested control subject model finetuned on patient data was performing better than on control data. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
